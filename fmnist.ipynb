{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(r\"C:\\Users\\Asaf Yekutiel\\Desktop\\data\\fmnist_data\\fashion-mnist_train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>87</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>99</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>137</td>\n",
       "      <td>126</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>105</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>136</td>\n",
       "      <td>155</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>57</td>\n",
       "      <td>70</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      0       0       0       0       0       0       0       0       9   \n",
       "1      1       0       0       0       0       0       0       0       0   \n",
       "2      2       0       0       0       0       0       0      14      53   \n",
       "3      2       0       0       0       0       0       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "5      2       0       0       0       0       0      44     105      44   \n",
       "6      8       0       0       0       0       0       0       0       0   \n",
       "7      6       0       0       0       0       0       0       0       1   \n",
       "8      5       0       0       0       0       0       0       0       0   \n",
       "9      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       8  ...       103        87        56         0         0         0   \n",
       "1       0  ...        34         0         0         0         0         0   \n",
       "2      99  ...         0         0         0         0        63        53   \n",
       "3       0  ...       137       126       140         0       133       224   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "5      10  ...       105        64        30         0         0         0   \n",
       "6       0  ...         0         0         0         0         0         0   \n",
       "7       0  ...       174       136       155        31         0         1   \n",
       "8       0  ...         0         0         0         0         0         0   \n",
       "9       0  ...        57        70        28         0         2         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2        31         0         0         0  \n",
       "3       222        56         0         0  \n",
       "4         0         0         0         0  \n",
       "5         0         0         0         0  \n",
       "6         0         0         0         0  \n",
       "7         0         0         0         0  \n",
       "8         0         0         0         0  \n",
       "9         0         0         0         0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(r\"C:\\Users\\Asaf Yekutiel\\Desktop\\data\\fmnist_data\\fashion-mnist_test.csv\")\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16fc9ad7c40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='label', data=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can see that the data is perfectly balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= train_data[\"label\"]\n",
    "X= train_data.drop(labels = [\"label\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/ 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size = 0.1, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training some models before PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(n_estimators=100,criterion='gini')\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score( y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBClassifier(n_estimators = 20,n_jobs = -1,learning_rate = 0.5, seed = 0)\n",
    "xgb_reg.fit(X_train,y_train)\n",
    "y_pred = xgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we cant see much difrennt between the models \n",
    " now lets pca and some fine tuning to improve and accelerate the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 85\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized',whiten=True).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f252b0ffd0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(n_estimators=150,criterion='gini',)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "y_pred=clf.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8668333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:51:41] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { cv } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asaf Yekutiel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:51:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.8828333333333334\n"
     ]
    }
   ],
   "source": [
    "xgb_reg = xgb.XGBClassifier(n_estimators = 180,n_jobs = -1,learning_rate = 0.5, seed = 0 ,cv =5,max_depth=18)\n",
    "xgb_reg.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = xgb_reg.predict(X_test_pca)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'learning_rate':[ 0.1, 0.2, 0.3],\n",
    "        'n_estimators':[100,150,200,250],\n",
    "        'min_child_weight': [1,3, 5,7, 10],\n",
    "        'gamma': [0,0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6,0.7, 0.8, 0.9, 1.0],\n",
    "        'max_depth': [3, 4, 5,8]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asaf Yekutiel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:54:27] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.8768333333333334\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(subsample=0.6, n_estimators=100, min_child_weight=5, max_depth=5, learning_rate=0.2, gamma=1.5, colsample_bytree=0.8,)\n",
    "xgb.fit(X_train_pca, y_train)\n",
    "y_pred = xgb.predict(X_test_pca)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = clf\n",
    "gbrt = GradientBoostingClassifier()\n",
    "xg  =  xgb_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asaf Yekutiel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:57:27] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { cv } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[08:57:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asaf Yekutiel\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:31:19] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { cv } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:31:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:34:33] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { cv } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:34:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:37:48] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { cv } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:37:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:41:04] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { cv } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:41:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[09:44:21] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { cv } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[09:44:24] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asaf Yekutiel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance for Training set\n",
      "- Accuracy: 1.0\n",
      "- MCC: 1.0\n",
      "- F1 score: 1.0\n",
      "----------------------------------\n",
      "Model performance for Test set\n",
      "- Accuracy: 0.8833333333333333\n",
      "- MCC: 0.8703862975563283\n",
      "- F1 score: 0.8828500757927549\n"
     ]
    }
   ],
   "source": [
    "estimator_list = [\n",
    "    ('rf',rf),\n",
    "    ('xg',xg),\n",
    "     ('gbrt',gbrt),\n",
    "]\n",
    "\n",
    "# Build stack model\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=estimator_list, final_estimator=LogisticRegression(),cv =5\n",
    ")\n",
    "stack_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = stack_model.predict(X_train_pca)\n",
    "y_test_pred = stack_model.predict(X_test_pca)\n",
    "\n",
    "# Training set model performance\n",
    "stack_model_train_accuracy = accuracy_score(y_train, y_train_pred) # Calculate Accuracy\n",
    "stack_model_train_mcc = matthews_corrcoef(y_train, y_train_pred) # Calculate MCC\n",
    "stack_model_train_f1 = f1_score(y_train, y_train_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "# Test set model performance\n",
    "stack_model_test_accuracy = accuracy_score(y_test, y_test_pred) # Calculate Accuracy\n",
    "stack_model_test_mcc = matthews_corrcoef(y_test, y_test_pred) # Calculate MCC\n",
    "stack_model_test_f1 = f1_score(y_test, y_test_pred, average='weighted') # Calculate F1-score\n",
    "\n",
    "print('Model performance for Training set')\n",
    "print('- Accuracy: %s' % stack_model_train_accuracy)\n",
    "print('- MCC: %s' % stack_model_train_mcc)\n",
    "print('- F1 score: %s' % stack_model_train_f1)\n",
    "print('----------------------------------')\n",
    "print('Model performance for Test set')\n",
    "print('- Accuracy: %s' % stack_model_test_accuracy)\n",
    "print('- MCC: %s' % stack_model_test_mcc)\n",
    "print('- F1 score: %s' % stack_model_test_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testdata = test_data.drop(labels = [\"label\"], axis = 1) \n",
    "y_testdata = test_data[\"label\"]\n",
    "X_testdata = X_testdata/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reduced = pca.transform(X_testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Algo Result :  0.8823\n"
     ]
    }
   ],
   "source": [
    "final_xgb = xgb_reg.predict(X_test_reduced)\n",
    "print(\"XGBoost Algo Result : \",xgb_reg.score(X_test_reduced,y_testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stack model Algo Result :  0.8829\n"
     ]
    }
   ],
   "source": [
    "final_stack = stack_model.predict(X_test_reduced)\n",
    "print(\"stack model Algo Result : \",stack_model.score(X_test_reduced,y_testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
